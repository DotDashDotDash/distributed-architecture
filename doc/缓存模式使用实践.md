# 分布式架构—缓存模式使用实践

-------------------------

## 1. 分布式缓存的两大模式

分布式缓存的设计模板主要有两大类:

* <font color=#FF1CAE>`Cache-Aside`</font>
* <font color=#FF1CAE>`Cache-As-SoR`</font>
  * <font color=\#38B0DE>`Read-Through`</font>
  * <font color=\#38B0DE>`Write-Through`</font>
  * <font color=\#38B0DE>`Write-Behind`</font>

**SoR(System-of-Record)** 指的是记录系统，或者叫做数据源，即实际存储原始数据的系统，在大多数实际生产环境中指的是数据库

**Cache**指的是缓存，是SoR的快照数据，Cache的访问速度比SoR要快

**回源**指回到数据源头，大部分情况下指的是查询数据库

## 2. Cache-Aside模式

### 2.1 Cache-Aside流程

Cache-Aside整个业务代码围绕着Cache展开，由业务代码直接维护Cache，**读场景**伪代码如下:

```java
//step1: 从缓存中获取数据
value = cache.getIfPresent(key);

if(value == null){
    //step2: 缓存没有命中，则回源至SoR获取源数据
    value = soR.getIfPresent(key);
    //step3: 将新读出的数据放置到cache中
    cache.put(key, value);
}
```

**写场景**的伪代码如下

```java
//step1: 先将数据写入到SoR中
soR.write(key, value);
//step2: 使cache中原有的数据失效，下次读取的时候再写入到cache中
cache.invalidate(key);
```

Cache-Aside模式更适合用AOP模式实现，具体的可以去参考Spring Cache的具体实现，着重了解`@Cache`, `@CachePut`, `@CacheEvict`等注解工作原理。

### 2.2 Cache-Aside存在的问题

* Cache-Aside模式存在并发更新的情况，如果是多个应用实例同时更新，怎么办？
* Cache-Aside模式下，key的过期时间设置为多少合适？

针对并发访问同时更新的情况，视数据的类别而定：

1. 若更新的数据是用户的维度，例如用户的订单数据等，在短时间内面临修改的可能性不大，因此绝大多数情况下不需要去考虑这种情况，**只需要设置数据一定的过期时间即可**
2. 若更新的数据是商品等的基础数据，在短时间内可能会面临大量访问的数据，可以使用canal订阅binlog，来进行增量更新分布式缓存，这样不会出现缓存数据不一致的情况。但是缓存更新存在延迟，而本地缓存可根据不一致容忍度设置合理的过期时间。[canal(基于mysql数据库binlog的增量订阅&消费)](https://www.jianshu.com/p/6299048fad66)
3. 读服务场景下，可以考虑一致性哈希算法，**将相同操作负载均衡到同一个实例当中，从而减少并发几率，或者设置比较短的额过期时间。参考[京东商品详情页服务闭环实践](京东商品详情页服务闭环实践.md)

## 3. Cache-As-SoR模式

Cache-As-SoR从字面意思理解，即所有的操作都是对Cache进行的，之后再**委托Cache对SoR进行真正的读写**，业务代码看不到SoR的操作。具体的有3中实现方式：`read-through`，`write-through`，`write-behind`

### 3.1 Read-Through

业务代码首先调用Cache，Cache不命中由Cache回源到SoR，这种模式下，需要配置一个`CacheLoader`组件用来回源，Guava Cache和EhCache3.x都支持该模式

```java
//Guava Cache实现
LoadingCache<Integer, Result<Category>> cache = CacheBuilder.newBuilder()
    .softValues()	//软引用方便GC，节省堆空间
    .maximumSize(5000).expireAfterWrite(2, TimeUnit.MINUTES)
    .build(new CacheLoader<Integer, Result<Category>>(){
        @Override
        public Result<Category> load(final Integer sortId) throws Exception{
            return categoryService.get(sortId);	//从SoR中获取Category
        }
    });

//EhCache3.x实现
CacheManager cacheManager = CacheManagerBuilder.newCacheManagerBuilder().build(true);

Cache<String, String> cache = cacheManager.createCache("cache1",
            	//中间省略其他配置
                .withLoaderWriter(new DefaultCacheLoaderWriter<String, String>(){	//重点，Loader回源
                    @Override
                    public String load(String key) throws Exception{
                        return readDB(key);
                    }
                    
                    @Override
                    public Map<String, String> loadAll(Iterable<? extends String> keys)
                        throws Exception{
                        return null;	//暂时不处理
                    }
                }));                                       
```

在应用层，代码直接调用`cache#get(sortId)`，首先查询Cache，若缓存命中，直接返回缓存数据，如果Cache没有命中，由CacheLoader回源到SoR去获取，回源操作调用`categoryService#get(sortId)`

**`Read-Through`存在Dog-pile Effect问题：当某个缓存失效，又有大量的请求没有命中缓存，从而使请求到达后端，导致后端压力变大。**

解决Dog-pile Effect的方法有很多，**其中一个就是在众多的请求当中限定一个请求访问SoR拿到数据即可**

```java
//解决Dog-pile Effect
if(firstCreateNewEntry){	//第一个到达的请求去加载SoR中的数据
    try{
        synchronized(e){
            return loadSync(key, hash, loadingValueReference, loader);
        }
    }finally{
        statsCounter.recordMisses(1);
    }
}else{	//大家在这里等等，前面有人去拿了
    return waitForLoadingValue(e, key, valueReference);
}
```

利用EhCache3.x解决Dog-pile Effect代码见[cache/cache-pattern模块](../cache/cache-pattern/)

### 3.2 Write-Through

Write-Through又称**穿透写/直写模式**，业务代码调用Cache写，然后由Cache负责写缓存和写SoR，而不是由业务代码。使用Write-Through模式需要配置一个CacheWriter组件用来写缓存和SoR。**EhCache3.x可利用CacheLoaderWriter来同步SoR，同步成功之后会更新缓存**

```java
//EhCache3.x实现
CacheManager cacheManager = CacheManagerBuilder.newCacheManagerBuilder().build(true);

Cache<String, String> cache = cacheManager.createCache("cache1",
            	//中间省略其他配置
                .withLoaderWriter(new DefaultCacheLoaderWriter<String, String>(){
                    @Override
                    public void write(String key, String data){}
                    
                    @Override
                    public void writeAll(...){}
                    
                    @Override
                    public void delete(...){}
                    
                    @Override
                    public void deleteAll(...){}
                }).build());
```

可以看到Write-Through和Read-Through的LoaderWriter是相同或的，但是一个负责读，一个负责写

### 3.3 Write-Behind

Write-Behind为回写模式，是**异步写**，异步之后可以实现批量写，合并写，延时和限流

* **异步写**

```java
acheManager cacheManager = CacheManagerBuilder.newCacheManagerBuilder().build(true);

Cache<String, String> cache = cacheManager.createCache("cache1",
            	//中间省略其他配置
                .withLoaderWriter(new DefaultCacheLoaderWriter<String, String>(){
                	new DefaultLoaderWriter<String, String>(){
                        @Override
                        public void write(String key, String data){}
                        
                        @Override
                        public void delete(String key){}
                    }
                }).add(WriterBehindConfigurationBuilder
                      .newUnBatchedWriteBehindConfiguration()	//Un-Batch意味着所有批量操作都会转换成单个操作
                      .queueSize(5)			//异步队列容量
                      .concurrencyLevel(2)	//多少个并发线程在WriteBehind
                      .useThreadPool("xxx")	//线程池
                      .build()));
```

* **批量写**

```java
.withLoaderWriter(new DefaultCacheLoaderWriter<String, String>(){
    @Override
    public void writeAll(...){	//batch wirte  }
    
    @Override
    public void deleteAll(...){	//batch delete }
}).add(WriterBehindConfigurationBuilder
      .newBatchedWriteBehindConfiguration(3, TimeUnit...))	//批处理最大延迟
      .queueSize(5)
      .concurrencyLevel(1)
      .enableCoalescing()		//是否需要合并写，即对于相同的key只进行最后一次数据的记录
      .useThreadPool("xxx")
      .build()));
```

### 3.4 Copy Pattern

没什么好说的，分为两种，`Copy-On-Read`和`Copy-On-Write`

**但是需要注意！！！！Guava Cache和EhCache都是基于引用的，如果有人拿到缓存的数据并且修改，那么将会出现大问题**

